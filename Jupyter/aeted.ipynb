{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import imgproc\n",
    "from torchvision.transforms.functional import InterpolationMode as IMode\n",
    "from Model.aetad import AETAD_4Direct\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "AETAD_4Direct(\n  (_downscaling): Sequential(\n    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): _ReversePixelShuffle_(downscale_factor=4)\n  )\n  (_res_en1): _Resblock_(\n    channels=64\n    (filter_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (_res_en2): _Resblock_(\n    channels=64\n    (filter_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (_res_en3): _Resblock_(\n    channels=64\n    (filter_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (_conv_en1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (_conv_en2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (_conv_de1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (_res_de1): _Resblock_(\n    channels=64\n    (filter_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (_res_de2): _Resblock_(\n    channels=64\n    (filter_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (_res_de3): _Resblock_(\n    channels=64\n    (filter_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (_conv_de2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (_upscaling): Sequential(\n    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): PixelShuffle(upscale_factor=4)\n    (2): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AETAD_4Direct()\n",
    "checkpoint = torch.load('./jupyter_pth/aeted/g-best.pth', map_location='cuda:0')\n",
    "checkpoint = {k.replace('module.',''):v for k,v in checkpoint.items()}\n",
    "# model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 1596)\n"
     ]
    }
   ],
   "source": [
    "image_dir = './jupyter_src/pic/0822.png'\n",
    "image = Image.open(image_dir)\n",
    "# hr_transforms = transforms.CenterCrop(96)\n",
    "hr_image = image\n",
    "lr_transforms = transforms.Resize([hr_image.size[1]//4, hr_image.size[0]//4] , interpolation=IMode.BICUBIC)\n",
    "\n",
    "print(hr_image.size)\n",
    "hr_image.save('./jupyter_res/pic/origin.png')\n",
    "hr_image.show('Original')\n",
    "lr_image = lr_transforms(hr_image)\n",
    "lr_image.show(\"BICUBIC\")\n",
    "lr_image.save('./jupyter_res/pic/bicubic.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1596, 2040])\n",
      "tensor([[[[-0.6297, -0.4376, -0.4379,  ..., -0.0768, -0.0608, -0.0952],\n",
      "          [-0.2343, -0.1259, -0.1129,  ...,  0.0040, -0.0063, -0.0272],\n",
      "          [-0.2785, -0.1826, -0.1844,  ...,  0.0047, -0.0054, -0.0165],\n",
      "          ...,\n",
      "          [-0.1604, -0.2137, -0.2321,  ..., -0.2571, -0.3173, -0.2363],\n",
      "          [-0.2705, -0.2138, -0.2395,  ...,  0.2368, -0.1646, -0.4273],\n",
      "          [-0.0780, -0.2352, -0.2815,  ...,  0.0117, -0.2528, -0.2609]],\n",
      "\n",
      "         [[ 0.0992, -0.0558, -0.1085,  ..., -0.0316, -0.0403, -0.0079],\n",
      "          [ 0.0280, -0.1632, -0.1688,  ..., -0.0486, -0.0432, -0.0202],\n",
      "          [ 0.0233, -0.1378, -0.1503,  ..., -0.0590, -0.0497, -0.0299],\n",
      "          ...,\n",
      "          [-0.4534,  0.0018, -0.0100,  ...,  0.1248,  0.3744, -0.0443],\n",
      "          [-0.1614,  0.0139, -0.0783,  ..., -0.0947, -0.1627,  0.0208],\n",
      "          [-0.0245, -0.0442,  0.0838,  ..., -0.1062, -0.1327,  0.1078]],\n",
      "\n",
      "         [[-0.4043, -0.3809, -0.3187,  ..., -0.0192, -0.0268, -0.0303],\n",
      "          [-0.2742, -0.2826, -0.2302,  ...,  0.0032,  0.0061,  0.0007],\n",
      "          [-0.2776, -0.2590, -0.2518,  ...,  0.0211,  0.0270,  0.0358],\n",
      "          ...,\n",
      "          [-0.0770, -0.1307, -0.1347,  ...,  0.0549, -0.5645, -0.0816],\n",
      "          [-0.1595, -0.0717, -0.2145,  ...,  0.1054, -0.0259, -0.5683],\n",
      "          [-0.1733, -0.3805, -0.2888,  ...,  0.0426, -0.6772,  0.0186]]]])\n"
     ]
    }
   ],
   "source": [
    "hr_tensor = imgproc.image2tensor(hr_image, range_norm=False, half=False)\n",
    "lr_tensor = imgproc.image2tensor(lr_image, range_norm=False, half=False)\n",
    "print(hr_tensor.shape)\n",
    "with torch.no_grad():\n",
    "    hr_tensor = hr_tensor.reshape(1,3,1596,2040)\n",
    "    lr_tensor = lr_tensor.reshape(1,lr_tensor.shape[0], lr_tensor.shape[1], lr_tensor.shape[2])\n",
    "    down = model.encode(hr_tensor)\n",
    "    reveal = model.forward(hr_tensor)\n",
    "    print(down)\n",
    "    down_img = Image.fromarray(imgproc.tensor2image(F.normalize(-down, p=2, dim=1) , range_norm=False, half=False))\n",
    "    reveal_img = Image.fromarray(imgproc.tensor2image(reveal, range_norm=False, half=False))\n",
    "    down_img.show('down_result')\n",
    "    reveal_img.show('reveal_result')\n",
    "    down_img.save('./jupyter_res/pic/feature.png')\n",
    "    reveal_img.save('./jupyter_res/pic/reveal.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}